{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pittsburgh Crime Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are working with three datasets. \n",
    "\n",
    "1. Pittsburgh police blotter dataset obtained from https://data.wprdc.org/dataset/pittsburgh-police-incident-blotter\n",
    "The police blotter dataset is a listing of arrests in Pittsburgh documented shortly after an arrest is made. an arrest occurs but it does not include investigative, intelligence, nor treatment (medical) data. The information is \"semi-refined\" ie. a police report was taken, but it hadn't made its way through the court system nor the Uniform Crime Report.\n",
    "\n",
    "2. Census 2010 Data obtained from http://www.pittsburghpa.gov/dcp/snap/raw_data\n",
    "The Census data has demographic details of Pittsburgh. It breaks down the population by neighbourhoods and it gives the racial make up of each neighbourhood. It also gives the number of housing units in a neighbourhood and breaks it down by units occupied and vacant.\n",
    "\n",
    "3. QUANDL API - http://static.quandl.com/zillow/hood_codes.csv \n",
    "We are obtaining Median Home prices for neighbourhoods within Pittsburgh using the Quandl API. Each neighbourhood has a code which the Quandl API uses. All neighbourhood codes in the US have been stored into a file hood_codes.csv. We will map our neighbourhood names with the names in this file and then call the API using the code, to get us a median list of house prices for that neighbourhood.\n",
    "\n",
    "We combine these three datasets together to a final dataframe after cleaning and processing them.\n",
    "\n",
    "We would be analysing what attributes are significant for each types of crime and attempt trend analysis to find trends for the crimes occuring in Pittsburgh. We would find the statistically significant attributes by running hypothesis tests.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we import the libraries. We will be using urllib2 and BeautifulSoup to parse the HTML, and pandas for the csv processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib2\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "import quandl\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorizing Crimes\n",
    "Each crime in our dataset belongs to a category, or type, of crime. This category is labeled by the SECTION column. To map this SECTION number to the description of the type of crime, we need to parse the Pittsburgh crime website for this information. We did this by retrieving the HTML using urllib2, and use BeautifulSoup and regex pattern matching to obtain the section, or chapter, names and descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "web_page = urllib2.urlopen(\"http://www.legis.state.pa.us/WU01/LI/LI/CT/htm/18/18.htm\").read()\n",
    "soup = BeautifulSoup(web_page, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: u'General Provisions', 3: u'Culpability', 5: u'General Principles of Justification', 7: u'Responsibility (Reserved)', 9: u'Inchoate Crimes', 11: u'Authorized Disposition of Offenders', 13: u'Authority of Court in Sentencing (Transferred)', 21: u'Offenses Against the Flag', 23: u'General Provisions', 25: u'Criminal Homicide', 26: u'Crimes Against Unborn Child', 27: u'Assault', 29: u'Kidnapping', 30: u'Human Trafficking', 31: u'Sexual Offenses', 32: u'Abortion', 33: u'Arson, Criminal Mischief and Other Property Destruction', 35: u'Burglary and Other Criminal Intrusion', 37: u'Robbery', 39: u'Theft and Related Offenses', 41: u'Forgery and Fraudulent Practices', 43: u'Offenses Against the Family', 45: u'General Provisions', 47: u'Bribery and Corrupt Influence', 49: u'Falsification and Intimidation', 51: u'Obstructing Governmental Operations', 53: u'Abuse of Office', 55: u'Riot, Disorderly Conduct and Related Offenses', 57: u'Wiretapping and Electronic Surveillance', 59: u'Public Indecency', 61: u'Firearms and Other Dangerous Articles', 63: u'Minors', 65: u'Nuisances', 67: u'Proprietary and Official Rights', 69: u'Public Utilities', 71: u'Sports and Amusements', 73: u'Trade and Commerce', 75: u'Other Offenses', 76: u'Computer Offenses', 77: u'Vehicle Chop Shop and Illegally Obtained and Altered Property', 91: u'Criminal History Record Information', 92: u'Conflicts of Interest', 93: u'Independent Counsel (Repealed)', 94: u'Crime Victims', 95: u'Independent Counsel'}\n"
     ]
    }
   ],
   "source": [
    "descriptions = {}\n",
    "for chapter in soup.find_all(text=re.compile('Chapter .* \\xa0')):\n",
    "    chapter_split = chapter.split()\n",
    "    num = int(chapter_split[1][:-1])\n",
    "    desc = \" \".join(chapter_split[2:])\n",
    "    descriptions[num] = desc\n",
    "    \n",
    "print descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will load the csv file into a dataframe so we can process it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_id               int64\n",
      "REPORT_NAME      object\n",
      "CCR               int64\n",
      "SECTION          object\n",
      "DESCRIPTION      object\n",
      "ARREST_TIME      object\n",
      "ADDRESS          object\n",
      "NEIGHBORHOOD     object\n",
      "ZONE            float64\n",
      "AGE             float64\n",
      "GENDER           object\n",
      "dtype: object\n",
      "117717\n"
     ]
    }
   ],
   "source": [
    "Crime = pd.read_csv('Pittsburgh-Crime-Dataset.csv')\n",
    "print Crime.dtypes\n",
    "print len(Crime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then need to filter out all of the rows with bad section data, that have sections that don't correspond to crime categories properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81574\n"
     ]
    }
   ],
   "source": [
    "# Get only rows that have sections with numeric sections corresponding to the type of crime.\n",
    "cleaned = Crime[Crime.apply(lambda x: x['SECTION'].isdigit() and len(x['SECTION'])>=3, axis=1)]\n",
    "print len(cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We remove the last 2 digits of the section to retrieve the broader section number, and create columns for this broad section number and crime description, saving this to a new csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rishub_2\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72753\n"
     ]
    }
   ],
   "source": [
    "cleaned['CrimeNum'] = cleaned['SECTION'].apply(lambda x: int(x[:-2]))\n",
    "cleaned = cleaned[cleaned.apply(lambda x: x['CrimeNum'] in descriptions, axis=1)]\n",
    "cleaned['CrimeDescription'] = cleaned['CrimeNum'].apply(lambda x: descriptions[x])\n",
    "print len(cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can run interesting analysis now that we have the crimes categorized. For example, we can see the most common crimes that happened in Pittsburgh, the most common being Assault."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'Assault', 12660), (u'Theft and Related Offenses', 11248), (u'Robbery', 9778), (u'Arson, Criminal Mischief and Other Property Destruction', 7519), (u'Crime Victims', 5518)]\n"
     ]
    }
   ],
   "source": [
    "s=0\n",
    "d={}\n",
    "for (ind,sec) in cleaned.groupby('CrimeNum'):\n",
    "    d[descriptions[ind]] = len(sec)\n",
    "    s+=len(sec)\n",
    "top5crimes = Counter(d).most_common(5)\n",
    "print top5crimes\n",
    "\n",
    "# Crime Victims are \"crimes\" involving a self-inflicted injury, mental illness, false alarm, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Demographical Data\n",
    "\n",
    "We now use the Census data to extract demographical data to add to the crime data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Crime = cleaned\n",
    "Census= pd.read_csv('CensusData.csv')\n",
    "Census=Census.rename(columns = {'HOOD':'NEIGHBORHOOD'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Census dataframe has multiple rows for each neighbourhood divided into blocks. We want aggregated statistics for each neighbourhood. The following code groups and aggregates rows together based on the neighbourhood name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hood = Census.groupby(['NEIGHBORHOOD'])\n",
    "censusAggdf = hood.agg(np.sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Renaming columns and deleting columns that are insignificant for our analysis either due to very large number of missing values, meaningless identification codes or values that are too small  compared to the corresponding values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "censusAggdf = pd.DataFrame(censusAggdf)\n",
    "\n",
    "del censusAggdf['TRACT']\n",
    "del censusAggdf['CENSUS CODE']\n",
    "del censusAggdf['BLOCK GRP']\n",
    "del censusAggdf['ONERACE']\n",
    "del censusAggdf['ONERACE18+']\n",
    "del censusAggdf['2+RACES+']\n",
    "del censusAggdf['2+RACES18+']\n",
    "del censusAggdf['OTHER']\n",
    "del censusAggdf['OTHER18+']\n",
    "\n",
    "\n",
    "censusAggdf=censusAggdf.rename(columns = {'OCCUP':'occupied','VACANT':'vacant'})\n",
    "\n",
    "censusAggdf.reset_index(level=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We join the two dataframes based on the neighbourhood. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pittdf = pd.merge(Crime,censusAggdf,  how='inner', on=['NEIGHBORHOOD'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting dataset looks like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     _id  REPORT_NAME       CCR SECTION  \\\n",
      "0  53961  OFFENSE 2.0  15158500     903   \n",
      "1  53962  OFFENSE 2.0  15158500    6106   \n",
      "2  53963  OFFENSE 2.0  15158500    3925   \n",
      "3  55262  OFFENSE 2.0  15162081    9490   \n",
      "4  54418       ARREST  15147051    3304   \n",
      "\n",
      "                                     DESCRIPTION          ARREST_TIME  \\\n",
      "0                           Criminal Conspiracy.  2015-08-22T23:59:00   \n",
      "1  Firearms not to be Carried without a License.  2015-08-22T23:59:00   \n",
      "2                     Receiving Stolen Property.  2015-08-22T23:59:00   \n",
      "3                  Missing Persons (18 and Over)  2015-08-27T23:10:00   \n",
      "4                             Criminal Mischief.  2015-08-24T01:48:00   \n",
      "\n",
      "                  ADDRESS      NEIGHBORHOOD  ZONE   AGE   ...   WHITE18+  \\\n",
      "0  400 block East Commons  Allegheny Center   1.0   NaN   ...        361   \n",
      "1  400 block East Commons  Allegheny Center   1.0   NaN   ...        361   \n",
      "2  400 block East Commons  Allegheny Center   1.0   NaN   ...        361   \n",
      "3     200 block Ridge Ave  Allegheny Center   1.0   NaN   ...        361   \n",
      "4  200 block East Ohio St  Allegheny Center   1.0  40.0   ...        361   \n",
      "\n",
      "   BLACK BLACK18+  ASIAN  ASIAN18+  HISPANIC  HISPAN18+  # HOUS UNITS  \\\n",
      "0    453      330     56        51        27         19          1052   \n",
      "1    453      330     56        51        27         19          1052   \n",
      "2    453      330     56        51        27         19          1052   \n",
      "3    453      330     56        51        27         19          1052   \n",
      "4    453      330     56        51        27         19          1052   \n",
      "\n",
      "   occupied  vacant  \n",
      "0       542     510  \n",
      "1       542     510  \n",
      "2       542     510  \n",
      "3       542     510  \n",
      "4       542     510  \n",
      "\n",
      "[5 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "print pittdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Median House Prices by Neighbourhood\n",
    "We will use the Quandl API to get median house prices for each neighbourhood. Each neighbourhood has a code which the Quandl API uses. All neighbourhood codes in the US have been stored into a file hood_codes.csv. We will map our neighbourhood names with the names in this file and then call the API using the code, to get us a median list of house prices for that neighbourhood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "apiKey = \"nzKQCTmvvKxw5qLxsYxp\"\n",
    "quandl.ApiConfig.api_key = apiKey\n",
    "df_all = pittdf\n",
    "all_neighbourhoods = np.unique(df_all[\"NEIGHBORHOOD\"])\n",
    "hood_codes = pd.read_csv(\"hood_codes.csv\")\n",
    "hood_codes = hood_codes[[\"Region\",\"City|Code\",\"State\"]]\n",
    "hood_codes = hood_codes[hood_codes[\"State\"]==\"Pittsburgh\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hood_codes are of the type City|Code. We split this and just keep the value of Code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "code_list = []\n",
    "for i in hood_codes[\"City|Code\"]:\n",
    "    code_number = i.split(\"|\")\n",
    "    code_list.append(code_number[1])\n",
    "hood_codes[\"City|Code\"] = code_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are only interested in the codes in our dataset. So we form an intersection of all the codes that are in our dataset (clean_hoods) and the ones in the Quandl api (hood_codes) and then zip that with the name of the neighbourhoods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_hoods = []\n",
    "for i in all_neighbourhoods:\n",
    "    i = i.strip()\n",
    "    clean_hoods.append(i)\n",
    "    \n",
    "hood_set1 = set(clean_hoods)\n",
    "hood_set2 = set(hood_codes[\"Region\"])\n",
    "#missingHoods = hood_set1 - hood_set2\n",
    "found_hoods = hood_set1.intersection(hood_set2)\n",
    "\n",
    "all_list = []\n",
    "for i in found_hoods:\n",
    "    all_list.append(hood_codes[hood_codes[\"Region\"] == i][\"City|Code\"])\n",
    "    \n",
    "code_list = []\n",
    "for i in all_list:\n",
    "    z = i.get_values()\n",
    "    code_list.extend(z)\n",
    "\n",
    "named_codes = zip(code_list,found_hoods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can view how to call the Quandl API here - https://blog.quandl.com/api-for-housing-data\n",
    "We add the code number into the API get call of the form ZILL/N(code)_MSP and store the results of each call into a list. In case that there are no sale prices available for that HTTP, it will throw an error. We catch the error and save its median sale price as no_data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53\n"
     ]
    }
   ],
   "source": [
    "msp_list = []\n",
    "counter=0\n",
    "for i in code_list:\n",
    "    try:\n",
    "        median_sale_price = \"ZILL/N\"+i+\"_MSP\"\n",
    "        msp_df = quandl.get(median_sale_price)\n",
    "        msp_list.append(msp_df)\n",
    "    except:\n",
    "        msp_list.append(\"no_data\")\n",
    "        counter+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the name of the hoods and the MSP list into a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "values = zip(found_hoods,msp_list)\n",
    "median_dict = {}\n",
    "for i,v in values:\n",
    "    if(type(v)!=str):\n",
    "        median_dict[i]=v\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take the latest value for the neighbourhood as our MSP and store it in the dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for k,v in median_dict.iteritems():\n",
    "    v = v.tail(1)\n",
    "    v = v.get_values()\n",
    "    median_dict[k] = v[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rishub_2\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "finalDF = pittdf[pittdf.apply(lambda x: x['NEIGHBORHOOD'] in median_dict, axis=1)]\n",
    "finalDF['median_val'] = finalDF['NEIGHBORHOOD'].apply(lambda x: median_dict[x])\n",
    "print len(finalDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what the final dataframe looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        _id  REPORT_NAME       CCR SECTION  \\\n",
      "5084  53990  OFFENSE 2.0  15158254    3929   \n",
      "5085  54218  OFFENSE 2.0  15158953    3745   \n",
      "5086  54727  OFFENSE 2.0  15159964    3743   \n",
      "5087  54736  OFFENSE 2.0  15160133    3745   \n",
      "5088  54986  OFFENSE 2.0  15161088    3745   \n",
      "\n",
      "                                            DESCRIPTION          ARREST_TIME  \\\n",
      "5084                                      Retail Theft.  2015-08-22T17:30:00   \n",
      "5085  Accidents Involving Damage to Unattended Veh.o...  2015-08-23T10:00:00   \n",
      "5086  Accidents Involving Damage to Attended Veh. or...  2015-08-25T00:02:00   \n",
      "5087  Accidents Involving Damage to Unattended Veh.o...  2015-08-25T09:00:00   \n",
      "5088  Accidents Involving Damage to Unattended Veh.o...  2015-08-26T03:45:00   \n",
      "\n",
      "                      ADDRESS           NEIGHBORHOOD  ZONE  AGE     ...      \\\n",
      "5084     4100 block Butler St  Central Lawrenceville   2.0  NaN     ...       \n",
      "5085        100 block 43rd St  Central Lawrenceville   2.0  NaN     ...       \n",
      "5086     4000 block Butler St  Central Lawrenceville   2.0  NaN     ...       \n",
      "5087       44th St & Bruce St  Central Lawrenceville   2.0  NaN     ...       \n",
      "5088  Stanton Ave & Duncan St  Central Lawrenceville   2.0  NaN     ...       \n",
      "\n",
      "     BLACK  BLACK18+ ASIAN  ASIAN18+  HISPANIC  HISPAN18+  # HOUS UNITS  \\\n",
      "5084   422       285    78        61        78         58          2670   \n",
      "5085   422       285    78        61        78         58          2670   \n",
      "5086   422       285    78        61        78         58          2670   \n",
      "5087   422       285    78        61        78         58          2670   \n",
      "5088   422       285    78        61        78         58          2670   \n",
      "\n",
      "      occupied  vacant  median_val  \n",
      "5084      2293     377    145000.0  \n",
      "5085      2293     377    145000.0  \n",
      "5086      2293     377    145000.0  \n",
      "5087      2293     377    145000.0  \n",
      "5088      2293     377    145000.0  \n",
      "\n",
      "[5 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "print finalDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
